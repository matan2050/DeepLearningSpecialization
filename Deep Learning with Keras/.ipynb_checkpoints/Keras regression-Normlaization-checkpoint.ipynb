{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd315184",
   "metadata": {},
   "source": [
    "# Keras regression assignment\n",
    "## by Matan Weissbuch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d77c1e1a",
   "metadata": {},
   "source": [
    "importing all necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe2b45e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-07 23:13:29.228061: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13d7a9d2",
   "metadata": {},
   "source": [
    "load concrete data csv file from folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "273cce7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cement</th>\n",
       "      <th>Blast Furnace Slag</th>\n",
       "      <th>Fly Ash</th>\n",
       "      <th>Water</th>\n",
       "      <th>Superplasticizer</th>\n",
       "      <th>Coarse Aggregate</th>\n",
       "      <th>Fine Aggregate</th>\n",
       "      <th>Age</th>\n",
       "      <th>Strength</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1040.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>28</td>\n",
       "      <td>79.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1055.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>28</td>\n",
       "      <td>61.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>332.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>270</td>\n",
       "      <td>40.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>332.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>365</td>\n",
       "      <td>41.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>198.6</td>\n",
       "      <td>132.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>978.4</td>\n",
       "      <td>825.5</td>\n",
       "      <td>360</td>\n",
       "      <td>44.30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Cement  Blast Furnace Slag  Fly Ash  Water  Superplasticizer  \\\n",
       "0   540.0                 0.0      0.0  162.0               2.5   \n",
       "1   540.0                 0.0      0.0  162.0               2.5   \n",
       "2   332.5               142.5      0.0  228.0               0.0   \n",
       "3   332.5               142.5      0.0  228.0               0.0   \n",
       "4   198.6               132.4      0.0  192.0               0.0   \n",
       "\n",
       "   Coarse Aggregate  Fine Aggregate  Age  Strength  \n",
       "0            1040.0           676.0   28     79.99  \n",
       "1            1055.0           676.0   28     61.89  \n",
       "2             932.0           594.0  270     40.27  \n",
       "3             932.0           594.0  365     41.05  \n",
       "4             978.4           825.5  360     44.30  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('concrete_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b4c8e45",
   "metadata": {},
   "source": [
    "split data to prediction and target, or to independent variables (X) and dependent variable (y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9968ec00",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df[['Cement',\n",
    "        'Blast Furnace Slag',\n",
    "        'Fly Ash',\n",
    "        'Water', \n",
    "        'Superplasticizer',\n",
    "        'Coarse Aggregate', \n",
    "        'Fine Aggregate',\n",
    "        'Age']]\n",
    "\n",
    "y = df[['Strength']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab9a504c",
   "metadata": {},
   "source": [
    "define the function for creating the neural network, using the network properties as defined in the assignment instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14f66884",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define regression model\n",
    "def regression_model(n_cols):\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(10, activation='relu', input_shape=(n_cols,)))\n",
    "    model.add(Dense(1))\n",
    "    \n",
    "    # compile model\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b70fcc6d",
   "metadata": {},
   "source": [
    "normalize the data - subtract X values from the mean, and divide by the std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e45e937",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cement</th>\n",
       "      <th>Blast Furnace Slag</th>\n",
       "      <th>Fly Ash</th>\n",
       "      <th>Water</th>\n",
       "      <th>Superplasticizer</th>\n",
       "      <th>Coarse Aggregate</th>\n",
       "      <th>Fine Aggregate</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.476712</td>\n",
       "      <td>-0.856472</td>\n",
       "      <td>-0.846733</td>\n",
       "      <td>-0.916319</td>\n",
       "      <td>-0.620147</td>\n",
       "      <td>0.862735</td>\n",
       "      <td>-1.217079</td>\n",
       "      <td>-0.279597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.476712</td>\n",
       "      <td>-0.856472</td>\n",
       "      <td>-0.846733</td>\n",
       "      <td>-0.916319</td>\n",
       "      <td>-0.620147</td>\n",
       "      <td>1.055651</td>\n",
       "      <td>-1.217079</td>\n",
       "      <td>-0.279597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.491187</td>\n",
       "      <td>0.795140</td>\n",
       "      <td>-0.846733</td>\n",
       "      <td>2.174405</td>\n",
       "      <td>-1.038638</td>\n",
       "      <td>-0.526262</td>\n",
       "      <td>-2.239829</td>\n",
       "      <td>3.551340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.491187</td>\n",
       "      <td>0.795140</td>\n",
       "      <td>-0.846733</td>\n",
       "      <td>2.174405</td>\n",
       "      <td>-1.038638</td>\n",
       "      <td>-0.526262</td>\n",
       "      <td>-2.239829</td>\n",
       "      <td>5.055221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.790075</td>\n",
       "      <td>0.678079</td>\n",
       "      <td>-0.846733</td>\n",
       "      <td>0.488555</td>\n",
       "      <td>-1.038638</td>\n",
       "      <td>0.070492</td>\n",
       "      <td>0.647569</td>\n",
       "      <td>4.976069</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Cement  Blast Furnace Slag   Fly Ash     Water  Superplasticizer  \\\n",
       "0  2.476712           -0.856472 -0.846733 -0.916319         -0.620147   \n",
       "1  2.476712           -0.856472 -0.846733 -0.916319         -0.620147   \n",
       "2  0.491187            0.795140 -0.846733  2.174405         -1.038638   \n",
       "3  0.491187            0.795140 -0.846733  2.174405         -1.038638   \n",
       "4 -0.790075            0.678079 -0.846733  0.488555         -1.038638   \n",
       "\n",
       "   Coarse Aggregate  Fine Aggregate       Age  \n",
       "0          0.862735       -1.217079 -0.279597  \n",
       "1          1.055651       -1.217079 -0.279597  \n",
       "2         -0.526262       -2.239829  3.551340  \n",
       "3         -0.526262       -2.239829  5.055221  \n",
       "4          0.070492        0.647569  4.976069  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_norm = (x - x.mean()) / x.std()\n",
    "\n",
    "x_norm.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f88d2a",
   "metadata": {},
   "source": [
    "train and test the neural network for 50 times, and keep the MSE results for each training\n",
    "generate the test and train set of X (independent variables) from the normalized data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "07399ba1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: (721, 8) (721, 1)\n",
      "Test set: (309, 8) (309, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-07 23:15:23.274894: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-07 23:15:23.282726: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 8ms/step\n",
      "MSE 379.18\n",
      "Train set: (721, 8) (721, 1)\n",
      "Test set: (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 14ms/step\n",
      "MSE 325.17\n",
      "Train set: (721, 8) (721, 1)\n",
      "Test set: (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 12ms/step\n",
      "MSE 319.87\n",
      "Train set: (721, 8) (721, 1)\n",
      "Test set: (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 15ms/step\n",
      "MSE 251.69\n",
      "Train set: (721, 8) (721, 1)\n",
      "Test set: (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 12ms/step\n",
      "MSE 400.56\n",
      "Train set: (721, 8) (721, 1)\n",
      "Test set: (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 17ms/step\n",
      "MSE 486.26\n",
      "Train set: (721, 8) (721, 1)\n",
      "Test set: (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 10ms/step\n",
      "MSE 257.78\n",
      "Train set: (721, 8) (721, 1)\n",
      "Test set: (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 10ms/step\n",
      "MSE 306.20\n",
      "Train set: (721, 8) (721, 1)\n",
      "Test set: (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 9ms/step\n",
      "MSE 305.53\n",
      "Train set: (721, 8) (721, 1)\n",
      "Test set: (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 6ms/step\n",
      "MSE 251.72\n",
      "Train set: (721, 8) (721, 1)\n",
      "Test set: (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 7ms/step\n",
      "MSE 470.39\n",
      "Train set: (721, 8) (721, 1)\n",
      "Test set: (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 16ms/step\n",
      "MSE 292.92\n",
      "Train set: (721, 8) (721, 1)\n",
      "Test set: (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 11ms/step\n",
      "MSE 280.33\n",
      "Train set: (721, 8) (721, 1)\n",
      "Test set: (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 15ms/step\n",
      "MSE 316.09\n",
      "Train set: (721, 8) (721, 1)\n",
      "Test set: (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 7ms/step\n",
      "MSE 516.72\n",
      "Train set: (721, 8) (721, 1)\n",
      "Test set: (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 11ms/step\n",
      "MSE 331.84\n",
      "Train set: (721, 8) (721, 1)\n",
      "Test set: (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 12ms/step\n",
      "MSE 678.48\n",
      "Train set: (721, 8) (721, 1)\n",
      "Test set: (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 22ms/step\n",
      "MSE 308.34\n",
      "Train set: (721, 8) (721, 1)\n",
      "Test set: (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 11ms/step\n",
      "MSE 448.39\n",
      "Train set: (721, 8) (721, 1)\n",
      "Test set: (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 13ms/step\n",
      "MSE 330.36\n",
      "Train set: (721, 8) (721, 1)\n",
      "Test set: (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 14ms/step\n",
      "MSE 318.35\n",
      "Train set: (721, 8) (721, 1)\n",
      "Test set: (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 11ms/step\n",
      "MSE 402.85\n",
      "Train set: (721, 8) (721, 1)\n",
      "Test set: (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 9ms/step\n",
      "MSE 461.30\n",
      "Train set: (721, 8) (721, 1)\n",
      "Test set: (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 11ms/step\n",
      "MSE 267.37\n",
      "Train set: (721, 8) (721, 1)\n",
      "Test set: (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 4ms/step\n",
      "MSE 220.88\n",
      "Train set: (721, 8) (721, 1)\n",
      "Test set: (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 14ms/step\n",
      "MSE 432.15\n",
      "Train set: (721, 8) (721, 1)\n",
      "Test set: (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 11ms/step\n",
      "MSE 331.06\n",
      "Train set: (721, 8) (721, 1)\n",
      "Test set: (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 16ms/step\n",
      "MSE 300.20\n",
      "Train set: (721, 8) (721, 1)\n",
      "Test set: (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 5ms/step\n",
      "MSE 285.86\n",
      "Train set: (721, 8) (721, 1)\n",
      "Test set: (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 15ms/step\n",
      "MSE 285.16\n",
      "Train set: (721, 8) (721, 1)\n",
      "Test set: (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 12ms/step\n",
      "MSE 347.42\n",
      "Train set: (721, 8) (721, 1)\n",
      "Test set: (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 11ms/step\n",
      "MSE 473.77\n",
      "Train set: (721, 8) (721, 1)\n",
      "Test set: (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 11ms/step\n",
      "MSE 305.71\n",
      "Train set: (721, 8) (721, 1)\n",
      "Test set: (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 13ms/step\n",
      "MSE 397.55\n",
      "Train set: (721, 8) (721, 1)\n",
      "Test set: (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 16ms/step\n",
      "MSE 532.81\n",
      "Train set: (721, 8) (721, 1)\n",
      "Test set: (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 10ms/step\n",
      "MSE 360.24\n",
      "Train set: (721, 8) (721, 1)\n",
      "Test set: (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 12ms/step\n",
      "MSE 478.14\n",
      "Train set: (721, 8) (721, 1)\n",
      "Test set: (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 13ms/step\n",
      "MSE 429.97\n",
      "Train set: (721, 8) (721, 1)\n",
      "Test set: (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 12ms/step\n",
      "MSE 361.36\n",
      "Train set: (721, 8) (721, 1)\n",
      "Test set: (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 12ms/step\n",
      "MSE 382.79\n",
      "Train set: (721, 8) (721, 1)\n",
      "Test set: (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 10ms/step\n",
      "MSE 313.72\n",
      "Train set: (721, 8) (721, 1)\n",
      "Test set: (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 14ms/step\n",
      "MSE 272.54\n",
      "Train set: (721, 8) (721, 1)\n",
      "Test set: (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 10ms/step\n",
      "MSE 308.97\n",
      "Train set: (721, 8) (721, 1)\n",
      "Test set: (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 13ms/step\n",
      "MSE 477.64\n",
      "Train set: (721, 8) (721, 1)\n",
      "Test set: (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 13ms/step\n",
      "MSE 318.57\n",
      "Train set: (721, 8) (721, 1)\n",
      "Test set: (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 11ms/step\n",
      "MSE 293.11\n",
      "Train set: (721, 8) (721, 1)\n",
      "Test set: (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 11ms/step\n",
      "MSE 314.09\n",
      "Train set: (721, 8) (721, 1)\n",
      "Test set: (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 15ms/step\n",
      "MSE 283.11\n",
      "Train set: (721, 8) (721, 1)\n",
      "Test set: (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 15ms/step\n",
      "MSE 443.64\n",
      "Train set: (721, 8) (721, 1)\n",
      "Test set: (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 10ms/step\n",
      "MSE 322.42\n"
     ]
    }
   ],
   "source": [
    "n_split_iter = 50\n",
    "mse = np.zeros(n_split_iter)\n",
    "\n",
    "for i in range(n_split_iter):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "    x_norm, \n",
    "    y, \n",
    "    test_size=0.3, \n",
    "    random_state=4)\n",
    "\n",
    "    print ('Train set:', X_train.shape,  y_train.shape)\n",
    "    print ('Test set:', X_test.shape,  y_test.shape)\n",
    "\n",
    "    model = regression_model(8)\n",
    "    model.fit(X_train, y_train, epochs=50, verbose=0)\n",
    "    \n",
    "    yhat = model.predict(X_test)\n",
    "    \n",
    "    v = np.mean((yhat - y_test) ** 2)\n",
    "    mse[i] = v\n",
    "    print(\"MSE %.2f\" % v)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0250d5f8",
   "metadata": {},
   "source": [
    "analysis of the MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "96283069",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE mean: 359.61\n",
      "MSE std: 89.63\n"
     ]
    }
   ],
   "source": [
    "mse_mean = np.mean(mse)\n",
    "mse_std = np.std(mse)\n",
    "\n",
    "print(\"MSE mean: %.2f\" % mse_mean)\n",
    "print(\"MSE std: %.2f\" % mse_std)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
