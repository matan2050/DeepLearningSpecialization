{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd315184",
   "metadata": {},
   "source": [
    "# Keras regression assignment\n",
    "## by Matan Weissbuch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d77c1e1a",
   "metadata": {},
   "source": [
    "importing all necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe2b45e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-07 23:25:38.413157: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13d7a9d2",
   "metadata": {},
   "source": [
    "load concrete data csv file from folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "273cce7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cement</th>\n",
       "      <th>Blast Furnace Slag</th>\n",
       "      <th>Fly Ash</th>\n",
       "      <th>Water</th>\n",
       "      <th>Superplasticizer</th>\n",
       "      <th>Coarse Aggregate</th>\n",
       "      <th>Fine Aggregate</th>\n",
       "      <th>Age</th>\n",
       "      <th>Strength</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1040.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>28</td>\n",
       "      <td>79.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1055.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>28</td>\n",
       "      <td>61.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>332.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>270</td>\n",
       "      <td>40.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>332.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>365</td>\n",
       "      <td>41.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>198.6</td>\n",
       "      <td>132.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>978.4</td>\n",
       "      <td>825.5</td>\n",
       "      <td>360</td>\n",
       "      <td>44.30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Cement  Blast Furnace Slag  Fly Ash  Water  Superplasticizer  \\\n",
       "0   540.0                 0.0      0.0  162.0               2.5   \n",
       "1   540.0                 0.0      0.0  162.0               2.5   \n",
       "2   332.5               142.5      0.0  228.0               0.0   \n",
       "3   332.5               142.5      0.0  228.0               0.0   \n",
       "4   198.6               132.4      0.0  192.0               0.0   \n",
       "\n",
       "   Coarse Aggregate  Fine Aggregate  Age  Strength  \n",
       "0            1040.0           676.0   28     79.99  \n",
       "1            1055.0           676.0   28     61.89  \n",
       "2             932.0           594.0  270     40.27  \n",
       "3             932.0           594.0  365     41.05  \n",
       "4             978.4           825.5  360     44.30  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('concrete_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b4c8e45",
   "metadata": {},
   "source": [
    "split data to prediction and target, or to independent variables (X) and dependent variable (y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9968ec00",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df[['Cement',\n",
    "        'Blast Furnace Slag',\n",
    "        'Fly Ash',\n",
    "        'Water', \n",
    "        'Superplasticizer',\n",
    "        'Coarse Aggregate', \n",
    "        'Fine Aggregate',\n",
    "        'Age']]\n",
    "\n",
    "y = df[['Strength']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab9a504c",
   "metadata": {},
   "source": [
    "define the function for creating the neural network, using the network properties as defined in the assignment instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14f66884",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define regression model\n",
    "def regression_model(n_cols):\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(10, activation='relu', input_shape=(n_cols,)))\n",
    "    model.add(Dense(1))\n",
    "    \n",
    "    # compile model\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b70fcc6d",
   "metadata": {},
   "source": [
    "normalize the data - subtract X values from the mean, and divide by the std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e45e937",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cement</th>\n",
       "      <th>Blast Furnace Slag</th>\n",
       "      <th>Fly Ash</th>\n",
       "      <th>Water</th>\n",
       "      <th>Superplasticizer</th>\n",
       "      <th>Coarse Aggregate</th>\n",
       "      <th>Fine Aggregate</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.476712</td>\n",
       "      <td>-0.856472</td>\n",
       "      <td>-0.846733</td>\n",
       "      <td>-0.916319</td>\n",
       "      <td>-0.620147</td>\n",
       "      <td>0.862735</td>\n",
       "      <td>-1.217079</td>\n",
       "      <td>-0.279597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.476712</td>\n",
       "      <td>-0.856472</td>\n",
       "      <td>-0.846733</td>\n",
       "      <td>-0.916319</td>\n",
       "      <td>-0.620147</td>\n",
       "      <td>1.055651</td>\n",
       "      <td>-1.217079</td>\n",
       "      <td>-0.279597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.491187</td>\n",
       "      <td>0.795140</td>\n",
       "      <td>-0.846733</td>\n",
       "      <td>2.174405</td>\n",
       "      <td>-1.038638</td>\n",
       "      <td>-0.526262</td>\n",
       "      <td>-2.239829</td>\n",
       "      <td>3.551340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.491187</td>\n",
       "      <td>0.795140</td>\n",
       "      <td>-0.846733</td>\n",
       "      <td>2.174405</td>\n",
       "      <td>-1.038638</td>\n",
       "      <td>-0.526262</td>\n",
       "      <td>-2.239829</td>\n",
       "      <td>5.055221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.790075</td>\n",
       "      <td>0.678079</td>\n",
       "      <td>-0.846733</td>\n",
       "      <td>0.488555</td>\n",
       "      <td>-1.038638</td>\n",
       "      <td>0.070492</td>\n",
       "      <td>0.647569</td>\n",
       "      <td>4.976069</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Cement  Blast Furnace Slag   Fly Ash     Water  Superplasticizer  \\\n",
       "0  2.476712           -0.856472 -0.846733 -0.916319         -0.620147   \n",
       "1  2.476712           -0.856472 -0.846733 -0.916319         -0.620147   \n",
       "2  0.491187            0.795140 -0.846733  2.174405         -1.038638   \n",
       "3  0.491187            0.795140 -0.846733  2.174405         -1.038638   \n",
       "4 -0.790075            0.678079 -0.846733  0.488555         -1.038638   \n",
       "\n",
       "   Coarse Aggregate  Fine Aggregate       Age  \n",
       "0          0.862735       -1.217079 -0.279597  \n",
       "1          1.055651       -1.217079 -0.279597  \n",
       "2         -0.526262       -2.239829  3.551340  \n",
       "3         -0.526262       -2.239829  5.055221  \n",
       "4          0.070492        0.647569  4.976069  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_norm = (x - x.mean()) / x.std()\n",
    "\n",
    "x_norm.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f88d2a",
   "metadata": {},
   "source": [
    "train and test the neural network for 50 times, and keep the MSE results for each training\n",
    "generate the test and train set of X (independent variables) from the normalized data. this time, we run the training with 100 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "07399ba1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: (721, 8) (721, 1)\n",
      "Test set: (309, 8) (309, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-07 23:26:40.566374: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-07 23:26:40.579507: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 14ms/step\n",
      "MSE 183.28\n",
      "Train set: (721, 8) (721, 1)\n",
      "Test set: (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 14ms/step\n",
      "MSE 165.30\n",
      "Train set: (721, 8) (721, 1)\n",
      "Test set: (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 5ms/step\n",
      "MSE 185.86\n",
      "Train set: (721, 8) (721, 1)\n",
      "Test set: (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 17ms/step\n",
      "MSE 179.50\n",
      "Train set: (721, 8) (721, 1)\n",
      "Test set: (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 15ms/step\n",
      "MSE 166.35\n",
      "Train set: (721, 8) (721, 1)\n",
      "Test set: (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 17ms/step\n",
      "MSE 167.18\n",
      "Train set: (721, 8) (721, 1)\n",
      "Test set: (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 6ms/step\n",
      "MSE 186.24\n",
      "Train set: (721, 8) (721, 1)\n",
      "Test set: (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 11ms/step\n",
      "MSE 181.15\n",
      "Train set: (721, 8) (721, 1)\n",
      "Test set: (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 11ms/step\n",
      "MSE 173.50\n",
      "Train set: (721, 8) (721, 1)\n",
      "Test set: (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 14ms/step\n",
      "MSE 170.16\n",
      "Train set: (721, 8) (721, 1)\n",
      "Test set: (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 17ms/step\n",
      "MSE 196.62\n",
      "Train set: (721, 8) (721, 1)\n",
      "Test set: (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 11ms/step\n",
      "MSE 174.08\n",
      "Train set: (721, 8) (721, 1)\n",
      "Test set: (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 12ms/step\n",
      "MSE 180.71\n",
      "Train set: (721, 8) (721, 1)\n",
      "Test set: (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 10ms/step\n",
      "MSE 187.78\n",
      "Train set: (721, 8) (721, 1)\n",
      "Test set: (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 11ms/step\n",
      "MSE 175.04\n",
      "Train set: (721, 8) (721, 1)\n",
      "Test set: (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 11ms/step\n",
      "MSE 164.19\n",
      "Train set: (721, 8) (721, 1)\n",
      "Test set: (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 11ms/step\n",
      "MSE 186.96\n",
      "Train set: (721, 8) (721, 1)\n",
      "Test set: (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 13ms/step\n",
      "MSE 175.21\n",
      "Train set: (721, 8) (721, 1)\n",
      "Test set: (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 15ms/step\n",
      "MSE 167.77\n",
      "Train set: (721, 8) (721, 1)\n",
      "Test set: (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 11ms/step\n",
      "MSE 176.58\n",
      "Train set: (721, 8) (721, 1)\n",
      "Test set: (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 17ms/step\n",
      "MSE 175.33\n",
      "Train set: (721, 8) (721, 1)\n",
      "Test set: (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 10ms/step\n",
      "MSE 160.97\n",
      "Train set: (721, 8) (721, 1)\n",
      "Test set: (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 14ms/step\n",
      "MSE 193.89\n",
      "Train set: (721, 8) (721, 1)\n",
      "Test set: (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 11ms/step\n",
      "MSE 175.85\n",
      "Train set: (721, 8) (721, 1)\n",
      "Test set: (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 9ms/step\n",
      "MSE 251.44\n",
      "Train set: (721, 8) (721, 1)\n",
      "Test set: (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 16ms/step\n",
      "MSE 170.07\n",
      "Train set: (721, 8) (721, 1)\n",
      "Test set: (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 10ms/step\n",
      "MSE 194.77\n",
      "Train set: (721, 8) (721, 1)\n",
      "Test set: (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 14ms/step\n",
      "MSE 176.10\n",
      "Train set: (721, 8) (721, 1)\n",
      "Test set: (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 10ms/step\n",
      "MSE 164.45\n",
      "Train set: (721, 8) (721, 1)\n",
      "Test set: (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 11ms/step\n",
      "MSE 177.76\n",
      "Train set: (721, 8) (721, 1)\n",
      "Test set: (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 12ms/step\n",
      "MSE 188.73\n",
      "Train set: (721, 8) (721, 1)\n",
      "Test set: (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 11ms/step\n",
      "MSE 180.92\n",
      "Train set: (721, 8) (721, 1)\n",
      "Test set: (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 12ms/step\n",
      "MSE 181.96\n",
      "Train set: (721, 8) (721, 1)\n",
      "Test set: (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 10ms/step\n",
      "MSE 175.89\n",
      "Train set: (721, 8) (721, 1)\n",
      "Test set: (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 9ms/step\n",
      "MSE 175.71\n",
      "Train set: (721, 8) (721, 1)\n",
      "Test set: (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 10ms/step\n",
      "MSE 165.45\n",
      "Train set: (721, 8) (721, 1)\n",
      "Test set: (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 11ms/step\n",
      "MSE 179.34\n",
      "Train set: (721, 8) (721, 1)\n",
      "Test set: (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 12ms/step\n",
      "MSE 173.22\n",
      "Train set: (721, 8) (721, 1)\n",
      "Test set: (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 16ms/step\n",
      "MSE 168.19\n",
      "Train set: (721, 8) (721, 1)\n",
      "Test set: (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 10ms/step\n",
      "MSE 170.35\n",
      "Train set: (721, 8) (721, 1)\n",
      "Test set: (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 10ms/step\n",
      "MSE 164.29\n",
      "Train set: (721, 8) (721, 1)\n",
      "Test set: (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 18ms/step\n",
      "MSE 172.61\n",
      "Train set: (721, 8) (721, 1)\n",
      "Test set: (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 13ms/step\n",
      "MSE 164.38\n",
      "Train set: (721, 8) (721, 1)\n",
      "Test set: (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 12ms/step\n",
      "MSE 179.46\n",
      "Train set: (721, 8) (721, 1)\n",
      "Test set: (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 9ms/step\n",
      "MSE 176.71\n",
      "Train set: (721, 8) (721, 1)\n",
      "Test set: (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 12ms/step\n",
      "MSE 168.21\n",
      "Train set: (721, 8) (721, 1)\n",
      "Test set: (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 14ms/step\n",
      "MSE 169.67\n",
      "Train set: (721, 8) (721, 1)\n",
      "Test set: (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 14ms/step\n",
      "MSE 171.14\n",
      "Train set: (721, 8) (721, 1)\n",
      "Test set: (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 14ms/step\n",
      "MSE 171.79\n",
      "Train set: (721, 8) (721, 1)\n",
      "Test set: (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 12ms/step\n",
      "MSE 191.39\n"
     ]
    }
   ],
   "source": [
    "n_split_iter = 50\n",
    "mse = np.zeros(n_split_iter)\n",
    "\n",
    "for i in range(n_split_iter):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "    x_norm, \n",
    "    y, \n",
    "    test_size=0.3, \n",
    "    random_state=4)\n",
    "\n",
    "    print ('Train set:', X_train.shape,  y_train.shape)\n",
    "    print ('Test set:', X_test.shape,  y_test.shape)\n",
    "\n",
    "    model = regression_model(8)\n",
    "    model.fit(X_train, y_train, epochs=100, verbose=0)\n",
    "    \n",
    "    yhat = model.predict(X_test)\n",
    "    \n",
    "    v = np.mean((yhat - y_test) ** 2)\n",
    "    mse[i] = v\n",
    "    print(\"MSE %.2f\" % v)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0250d5f8",
   "metadata": {},
   "source": [
    "analysis of the MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "96283069",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE mean: 177.47\n",
      "MSE std: 13.65\n"
     ]
    }
   ],
   "source": [
    "mse_mean = np.mean(mse)\n",
    "mse_std = np.std(mse)\n",
    "\n",
    "print(\"MSE mean: %.2f\" % mse_mean)\n",
    "print(\"MSE std: %.2f\" % mse_std)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
